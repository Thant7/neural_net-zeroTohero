{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae45138-4e98-48ea-ba11-8b45c4b70978",
   "metadata": {
    "id": "cae45138-4e98-48ea-ba11-8b45c4b70978"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a8b170-231d-488e-a588-bbeaec7b1d5b",
   "metadata": {
    "id": "06a8b170-231d-488e-a588-bbeaec7b1d5b"
   },
   "outputs": [],
   "source": [
    "words = open('names.txt').read().splitlines()\n",
    "\n",
    "#build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "vocab_size = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "iGV91Gbocq8C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGV91Gbocq8C",
    "outputId": "fff006f7-9d51-4171-a232-150196288268"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "VmI8J0ihbH78",
   "metadata": {
    "id": "VmI8J0ihbH78"
   },
   "outputs": [],
   "source": [
    "# trian/ val/ test set splits\n",
    "def build_dataset(words):\n",
    "  block_size = 4 # context length: how many words do we take in to predict the next?\n",
    "  X, Y = [], []\n",
    "\n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix]\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor (Y)\n",
    "  return X,Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[:n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f6d801-2d03-438a-ab05-d72518cff6f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66f6d801-2d03-438a-ab05-d72518cff6f4",
    "outputId": "15a7e2ca-9873-4c2e-83ba-f0bbbbf9e8f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([182625, 4]),\n",
       " torch.Size([182625]),\n",
       " torch.Size([22655, 4]),\n",
       " torch.Size([22655]),\n",
       " torch.Size([205280, 4]),\n",
       " torch.Size([205280]),\n",
       " 25626,\n",
       " 28829)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape, Ytr.shape , Xdev.shape, Ydev.shape, Xte.shape, Yte.shape , n1, n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "664cac84-7828-47a7-a379-07dc3c314559",
   "metadata": {
    "id": "664cac84-7828-47a7-a379-07dc3c314559"
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27,20), generator = g, requires_grad = True)\n",
    "W1 = torch.randn((80,300), generator = g, requires_grad = True)\n",
    "b1 = torch.randn(300, generator = g, requires_grad = True)\n",
    "W2 = torch.randn((300,27), generator = g, requires_grad = True)\n",
    "b2 = torch.randn(27, generator = g, requires_grad = True)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ba7bc4-fe03-486d-9efa-4b5aafd1d782",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81ba7bc4-fe03-486d-9efa-4b5aafd1d782",
    "outputId": "9fa94532-9a31-40b8-ee88-fa3297b8725c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32967\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.nelement() for p in parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a44a27d9-8fc3-4516-9adf-1d30f1299dad",
   "metadata": {
    "id": "a44a27d9-8fc3-4516-9adf-1d30f1299dad"
   },
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "GCyZz8skh9HL",
   "metadata": {
    "id": "GCyZz8skh9HL"
   },
   "outputs": [],
   "source": [
    "lri = []\n",
    "lossi = []\n",
    "stepi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5dee9dc-dbce-4e0e-94cf-928a8afded1d",
   "metadata": {
    "id": "d5dee9dc-dbce-4e0e-94cf-928a8afded1d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(200000):\n",
    "\n",
    "    #mini-batch construct ; overfitting a random mini-batch size = 32\n",
    "    # mini-batch ----> lower quality gradient\n",
    "    # its better to calculate an estimate of gradient and make a few more steps\n",
    "    ix =  torch.randint(0, Xtr.shape[0], (64,))\n",
    "\n",
    "\n",
    "    #forward pass\n",
    "    emb = C[Xtr[ix]]\n",
    "    h = torch.tanh(emb.view(-1, 80) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    lr = 0.1 if i < 100000 else 0.01\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    #keeping track of stats\n",
    "    # lri.append(lre[i])\n",
    "    lossi.append(loss.log10().item())\n",
    "    stepi.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83LilkY_e8_q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83LilkY_e8_q",
    "outputId": "4ea32d85-3185-42bd-da65-e641e8b854ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2356367111206055\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tQFM2pqde-3V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "tQFM2pqde-3V",
    "outputId": "fbd1fa90-781c-4a21-9640-e0023d14485c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c92f3cd6a0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(stepi, lossi) # thickness because mini-batch creates a little bit of noise\n",
    "\n",
    "#one possible case is the batch size is too low that there is way too much noise in the training ---> play around with some batch size numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28LrmDJ2ebuB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28LrmDJ2ebuB",
    "outputId": "180621f2-62bd-4615-e729-c2e7e233acf0"
   },
   "outputs": [],
   "source": [
    "# emb = C[Xtr]\n",
    "# #forward pass\n",
    "# h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
    "# logits = h @ W2 + b2\n",
    "# loss = F.cross_entropy(logits, Ytr)\n",
    "# print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae12c8-aaf0-4d1c-9d65-97044327e852",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bae12c8-aaf0-4d1c-9d65-97044327e852",
    "outputId": "662a31df-f031-4418-a852-40fa0edba797"
   },
   "outputs": [],
   "source": [
    "emb = C[Xdev]\n",
    "#forward pass\n",
    "h = torch.tanh(emb.view(-1,60) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZeaYeb0e06f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "ZeaYeb0e06f6",
    "outputId": "1f98ea47-da2c-49b7-df2f-32c04117e34c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data from the provided configurations\n",
    "data = [\n",
    "    {\"iterations\": 400000, \"parameters\": 3487, \"loss\": 2.2, \"config\": \"embed_dim=2, batch=32\"},\n",
    "    {\"iterations\": 400000, \"parameters\": 11987, \"loss\": 2.23, \"config\": \"embed_dim=10, batch=32\"},\n",
    "    {\"iterations\": 400000, \"parameters\": 17697, \"loss\": 1.98, \"config\": \"embed_dim=10, batch=32\"},\n",
    "    {\"iterations\": 600000, \"parameters\": 26967, \"loss\": 1.67, \"config\": \"embed_dim=20, batch=32\"},\n",
    "    {\"iterations\": 400000, \"parameters\": 26967, \"loss\": 2.03, \"config\": \"embed_dim=20, batch=64\"},\n",
    "    {\"iterations\": 200000, \"parameters\": 26967, \"loss\": 1.92, \"config\": \"embed_dim=20, batch=64 (200k)\"}\n",
    "]\n",
    "\n",
    "# Create subplots with better spacing\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Iterations vs Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter([d[\"iterations\"] for d in data], [d[\"loss\"] for d in data], c='blue', s=150, edgecolors='black')\n",
    "plt.title('Iterations vs Loss', fontsize=16)\n",
    "plt.xlabel('Iterations', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "for d in data:\n",
    "    plt.annotate(d[\"config\"], (d[\"iterations\"], d[\"loss\"]),\n",
    "                 xytext=(5, 5), textcoords='offset points', fontsize=10, color='black')\n",
    "\n",
    "# Plot 2: Parameters vs Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter([d[\"parameters\"] for d in data], [d[\"loss\"] for d in data], c='red', s=150, edgecolors='black')\n",
    "plt.title('Parameters vs Loss', fontsize=16)\n",
    "plt.xlabel('Number of Parameters', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "for d in data:\n",
    "    plt.annotate(d[\"config\"], (d[\"parameters\"], d[\"loss\"]),\n",
    "                 xytext=(5, 5), textcoords='offset points', fontsize=10, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zT7jTOwygbYA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "zT7jTOwygbYA",
    "outputId": "bce05030-adfd-4568-a05b-9369b039f342"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "  plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
    "\n",
    "plt.grid('minor')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
